{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "import mobiquity as mq\n",
    "from mobiquity.names import *\n",
    "\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. OSM database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1. Census regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_region_db(name, overwrite=False):\n",
    "    name = name.lower().replace(' ', '-')\n",
    "    assert name in ['midwest', 'northeast', 'pacific', 'south', 'west'], name\n",
    "    outpath = DATA / f'osm/region/{name}.osm.pbf'\n",
    "    if outpath.exists() and not overwrite:\n",
    "        return\n",
    "    baseUrl = 'https://download.geofabrik.de/north-america'\n",
    "    url = f'{baseUrl}/us-{name}-latest.osm.pbf'\n",
    "    urllib.request.urlretrieve(url, U.mkfile(outpath))\n",
    "\n",
    "# download_region_db('pacific')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2. States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_state_db(name, overwrite=False):\n",
    "    name = name.lower().replace(' ', '-')\n",
    "    outpath = DATA / f'osm/state/{name}/{name}.osm.pbf'\n",
    "    if outpath.exists() and not overwrite:\n",
    "        return\n",
    "    baseUrl = 'https://download.geofabrik.de/north-america/us'\n",
    "    url = f'{baseUrl}/{name}-latest.osm.pbf'\n",
    "    urllib.request.urlretrieve(url, U.mkfile(outpath))\n",
    "\n",
    "# for state in tqdm(mk.geo.US_STATES_FIPS.keys()):\n",
    "#     download_state_db(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3. Extract regional database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# #! long time to run\n",
    "# cd ../data/osm/region\n",
    "# for rgn in midwest northeast south west; do\n",
    "#     outfile=$rgn.osm\n",
    "#     if [ -f $outfile ]; then osmium cat $rgn.osm.pbf -o $outfile; fi\n",
    "# done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Extract for MSAs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. Prepare MSA lists\n",
    "The 50 largest MSAs were manually assigned a US region label to allow extracting the MSA OSM database from the regional OSM extract instead of the state's extract since an MSA can span multiple states but lies in only one region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 rows x 2 cols; Memory: 0.0 MiB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cbsa</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>&lt;object&gt;</td>\n",
       "      <td>&lt;object&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Atlanta-Sandy Springs-Roswell, GA</td>\n",
       "      <td>south</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Austin-Round Rock-San Marcos, TX</td>\n",
       "      <td>south</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                cbsa    region\n",
       "                            <object>  <object>\n",
       "0  Atlanta-Sandy Springs-Roswell, GA     south\n",
       "1   Austin-Round Rock-San Marcos, TX     south"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "msa2rgn = U.load(DATA / 'msa2region.csv').disp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_msas = (\n",
    "    U.load(DATA / 'ses/acs/acs_2021.parquet',\n",
    "           filters=[('scale', '==', 'BG')], columns=['geoid', 'popu'])\n",
    "    .merge(urba, on='geoid').groupby('urba')['popu'].sum().astype(int)\n",
    "    .sort_values(ascending=False).reset_index()\n",
    "    .head(50))\n",
    "top_msas['msa'] = [x.split(',')[0].split('-')[0].split('/')[0]\n",
    "                   for x in top_msas['urba']]\n",
    "top_msas.disp(); pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Prepare GeoJSON\n",
    "Save the GeoJSON file of each MSA's boundary for the corresponding region for the `osmium extract` command to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_msa_json(year=2020, msa2rgn=msa2rgn, top_msas=topMSAs):\n",
    "    msa = top_msas.merge(msa2rgn, on='cbsa').rename(\n",
    "        columns=D(geoid='cbsa_id'))[['cbsa_id', 'key', 'region']]\n",
    "    df = gpd.read_parquet(DATA / f'zones/zones_{year}.parquet',\n",
    "                          filters=[('scale', '==', 'county')])\n",
    "    df = df.merge(msa, on='cbsa_id')\n",
    "    df = df[['key', 'region', 'geometry']]\n",
    "    df = df.dissolve('key').reset_index()\n",
    "    # for multipolygon features, keep only the largest polygon for simplicity\n",
    "    df = df.explode(subset='geometry', index_parts=True)\n",
    "    df['area'] = df.to_crs(CRS_M).area\n",
    "    df = df.sort_values('area').groupby('key').last()\n",
    "    for key, r in df.iterrows():\n",
    "        outpath = DATA / f'osm/msa/json/{r.region}/{key}.geojson'\n",
    "        df = Gdf(r.to_frame().T, crs=CRS_DEG)\n",
    "        df.to_file(U.mkfile(outpath), driver='GeoJSON')\n",
    "\n",
    "# get_msa_json() # t=0:14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3. Extract MSA database by region\n",
    "Using the `./get_msa_osm.sh` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
